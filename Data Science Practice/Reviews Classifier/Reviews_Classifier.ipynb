{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Project: Reviews Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I aim to build a model to classify Amazon reviews into classes. In particular deciding if reviews are Positive or Negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is provided as JSON, need JSON package to read data in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from reviewer import Review\n",
    "from data_optimiser import DataOptimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very large and contains more than 100,000 reviews, for performance, I'm going to only use 10000 reviews. Furthermore, I'll distribute the sentiments equally, ie each sentiment label will appear roughly an equal number of times in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "num_datapoints = 10000\n",
    "count = 0\n",
    "with open('./Data/Video_Games_5.json') as f:\n",
    "    for line in f:\n",
    "        if count <= num_datapoints:\n",
    "            count += 1 \n",
    "            json_line = json.loads(line)\n",
    "            data.append(Review(json_line['reviewText'],json_line['overall']))\n",
    "        else:\n",
    "            break "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data: 70% Train, 30% testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2562\n",
      "1124\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.3, train_size=0.7, random_state=10)\n",
    "train_reviews, train_sentiments = DataOptimizer(train_data).get_reviews_ratings()\n",
    "test_reviews, test_sentiments = DataOptimizer(test_data).get_reviews_ratings()\n",
    "print(len(train_reviews))\n",
    "print(len(test_reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using a \"Bag of Words\" method to extract the features from the reviews. Note that: CountVectorizer/TfidfVectorizer can fit and transform, the ouput is stored as a dense numpy array. Can use .toarray() to visualise if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = TfidfVectorizer()\n",
    "train_X = feature_extractor.fit_transform(train_reviews)\n",
    "test_X = feature_extractor.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fitting Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using GridSearch to optimize model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 2, 4, 10),\n",
       "                         'kernel': ('linear', 'rbf', 'sigmoid')})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel': ('linear', 'rbf', 'sigmoid'), 'C' : (1, 2, 4, 10)}\n",
    "support_vector_model = svm.SVC()\n",
    "tuned_model = GridSearchCV(support_vector_model, parameters, cv=5)\n",
    "tuned_model.fit(train_X, train_sentiments)\n",
    "tuned_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7428825622775801"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuned_model.score(test_X, test_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74447392 0.74127126]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_sentiments, tuned_model.predict(test_X), average=None, labels=['Positive', 'Negative']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Models/SVM_Games_Reviews.pkl', 'wb') as f:\n",
    "    pickle.dump(tuned_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Models/SVM_Games_Reviews.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Positive', 'Negative'], dtype='<U8')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_pos = 'This game was amazing, well worth the money'\n",
    "example_neg = 'Game was awful, total waste of money'\n",
    "examples = [example_pos, example_neg]\n",
    "vec_example = feature_extractor.transform(examples)\n",
    "loaded_model.predict(vec_example)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "742eda1bdf1e218a3bb2b4bc9aaa5c450f2dcf1623d3e127dc8dee9e2156d7e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

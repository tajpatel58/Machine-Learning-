{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLP Project: Reviews Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I aim to build a model to classify Amazon reviews into classes. In particular deciding if reviews are Positive, Negative or Neutral. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is provided as JSON, need JSON package to read data in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from reviewer import Review\n",
    "from data_optimiser import DataOptimizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open('./Data/Books_small_10000.json') as f:\n",
    "    for line in f:\n",
    "        json_line = json.loads(line)\n",
    "        data.append(Review(json_line['reviewText'],json_line['overall']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is very large and contains more than 100,000 reviews, for performance, I'm going to only use 9000 reviews. Furthermore, I'll distribute the sentiments equally, ie each sentiment label will appear roughly equal number of times in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data: 70% Train, 30% testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.3, train_size=0.7, random_state=10)\n",
    "train_reviews, train_sentiments = DataOptimizer(train_data).get_reviews_ratings()\n",
    "test_reviews, test_sentiments = DataOptimizer(test_data).get_reviews_ratings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll be using a \"Bag of Words\" method to extract the features from the reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = CountVectorizer()\n",
    "# Note that: CountVectorizer can fit and transform, the ouput is stored as a dense numpy array. Can use .toarray() to visualise if needed.\n",
    "train_X = feature_extractor.fit_transform(train_reviews)\n",
    "test_X = feature_extractor.transform(test_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit a few different models and we can use our model metrics to evaluate the effectiveness of each model. I'll create a model using an SVM and a Logistic model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vm = svm.SVC(kernel='linear').fit(train_X, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7792114695340502"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "support_vm.score(train_X, train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64705882 0.46060606 0.54054054]\n"
     ]
    }
   ],
   "source": [
    "print(f1_score(test_sentiments, support_vm.predict(test_X), average=None, labels=['Positive', 'Neutral', 'Negative']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "742eda1bdf1e218a3bb2b4bc9aaa5c450f2dcf1623d3e127dc8dee9e2156d7e1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
